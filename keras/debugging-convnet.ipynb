{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential, Graph, model_from_json\n",
    "from keras.layers.core import Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.visualize_util import to_graph\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "import cPickle\n",
    "from pprint import pprint\n",
    "\n",
    "import train\n",
    "import evaluate\n",
    "from train import infer_sizes\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load up our data H5 and grab some trained weights for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data and get a model\n",
    "train_h5_path = '../cache/train-patches-mpii/samples-000001.h5'\n",
    "train_neg_h5_path = '../cache/train-patches-mpii/negatives.h5'\n",
    "val_h5_path = '../cache/val-patches-mpii/samples-000001.h5'\n",
    "val_neg_h5_path = '../cache/val-patches-mpii/negatives.h5'\n",
    "train_h5 = h5py.File(train_h5_path, 'r')\n",
    "train_neg_h5 = h5py.File(train_neg_h5_path, 'r')\n",
    "val_h5 = h5py.File(val_h5_path, 'r')\n",
    "val_neg_h5 = h5py.File(val_neg_h5_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images, train_flow = train_h5['images'], train_h5['flow']\n",
    "train_neg_images, train_neg_flow = train_neg_h5['images'], train_neg_h5['flow']\n",
    "val_images, val_flow = val_h5['images'], val_h5['flow']\n",
    "val_neg_images, val_neg_flow = val_neg_h5['images'], val_neg_h5['flow']\n",
    "ds_shape = infer_sizes(train_h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, nesterov=True, momentum=0.9)\n",
    "model = models.vggnet16_joint_reg_class_flow(ds_shape, sgd, 'glorot_normal')\n",
    "model.load_weights('../cache/kcnn-flow-rgb-tripose-from-3840-plus-1024/model-iter-10240-r181250.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd2 = SGD(lr=0.0001, nesterov=True, momentum=0.9)\n",
    "poselet_model = models.vggnet16_poselet_class_flow(ds_shape, sgd2, 'glorot_normal')\n",
    "poselet_model.load_weights('../cache/kcnn-flow-rgb-poselet/model-iter-30208-r769004.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by doing a basic visualisation of our model and inspecting the shape of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print '# Data shapes'\n",
    "print 'images:', train_images.shape\n",
    "print 'flow:', train_flow.shape\n",
    "print 'validation images:', val_images.shape\n",
    "print 'validation flow:', val_flow.shape\n",
    "print\n",
    "print '# Network'\n",
    "SVG(to_graph(poselet_model, show_shape=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upgraded_poselet_model = models.upgrade_multipath_poselet_vggnet(poselet_model)\n",
    "assert poselet_model.loss, \"Model needs a non-empty loss\"\n",
    "upgraded_poselet_model.compile(sgd2, poselet_model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVG(to_graph(upgraded_poselet_model, show_shape=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and reloading models\n",
    "\n",
    "Need to check that my convert to fully convolutional network --> save model to JSON and weights to HDF5 --> reload model from Matlab pipeline works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_json = upgraded_poselet_model.to_json()\n",
    "with open('../cache/cnn_model.json', 'w') as fp:\n",
    "    fp.write(mod_json)\n",
    "upgraded_poselet_model.save_weights('../cache/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../cache/cnn_model.json') as fp:\n",
    "    json_data = fp.read()\n",
    "m2 = model_from_json(json_data)\n",
    "m2.load_weights('../cache/cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the training set (no predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write some functions to look at our data and also a few utilities for doing forward prop. These will be useful for inspecting activations and gradients, as well as verifying that I've written what I wanted to write to the file.\n",
    "\n",
    "Note that some of these images will look weird because they've been padded (where necessary) with their edge pixel values. This is true of the flow as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = loadmat('../cache/centroids.mat')['centroids'][0].tolist()\n",
    "\n",
    "def _label_to_coords(label):\n",
    "    if label.ndim == 1:\n",
    "        return label.reshape((-1, 2))\n",
    "    assert label.ndim == 2\n",
    "    return label.reshape((len(label), -1, 2))\n",
    "\n",
    "def get_centroids(classes, centroids):\n",
    "    \"\"\"Grab the centroid of the cluster associated with each classifier output.\n",
    "    \n",
    "    :param classes: One-of-K vector (N-first, K-second) indicating appropriate\n",
    "                    centroids\n",
    "    :param centroids: list of P elements, each of which is a CxJp array, where\n",
    "                      P is the number of poselets, C is the number of clusters\n",
    "                      per poselet, and Jp is the number of regressor outputs per\n",
    "                      cluster\n",
    "    :returns: N-element list of the form [(class, poselet, centroid)], where\n",
    "              class is in [0, P] (0 is background), centroid is None (for\n",
    "              background) or a Jp/2x2 array giving (x, y) locations for each\n",
    "              joint, and poselet is a poselet index in [0, C)\"\"\"\n",
    "    assert classes.ndim == 2, \"Expect one-of-K classes!\"\n",
    "    class_nums = np.argmax(classes, axis=1)\n",
    "    classes_per_poselet = (classes.shape[1] - 1) / len(centroids)\n",
    "    rv = []\n",
    "    \n",
    "    for num in class_nums:\n",
    "        if num == 0:\n",
    "            rv.append((0, None, None))\n",
    "            continue\n",
    "        poselet_class_idx = (num - 1) % classes_per_poselet\n",
    "        poselet = (num - 1) // classes_per_poselet\n",
    "        centroid = centroids[poselet][poselet_class_idx]\n",
    "        # Will have to fix this later, if I change number of\n",
    "        # points per poselet\n",
    "        assert centroid.shape == (16,)\n",
    "        rv.append((\n",
    "            poselet + 1, poselet_class_idx, _label_to_coords(centroid)\n",
    "        ))\n",
    "\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _reshape_im(im):\n",
    "    # images are stored channels-first, but numpy expects\n",
    "    # channels-last\n",
    "    return np.transpose(im, axes=(1, 2, 0))\n",
    "\n",
    "def _vis_flow(flow):\n",
    "    # clean visualisation of flow with angle of movement as\n",
    "    # hue, magnitude as saturation and a constant V of 1\n",
    "    x, y = flow\n",
    "    # normed-log makes things stand out quite a bit\n",
    "    mags = np.log(np.sqrt(x**2 + y**2) + 1)\n",
    "    norm_mags = mags / max(mags.flatten())\n",
    "    angles = (np.arctan2(x, y) + np.pi) / (2 * np.pi)\n",
    "    ones = np.ones_like(angles)\n",
    "    hsv = np.stack((angles, norm_mags, ones), axis=2)\n",
    "    return hsv_to_rgb(hsv)\n",
    "\n",
    "def _plot_coords(coords):\n",
    "    # plot a label corresponding to a flattened joint vector\n",
    "    for idx, coord in enumerate(coords):\n",
    "        plt.plot(coord[0], coord[1], marker='+')\n",
    "        plt.text(coord[0], coord[1], str(idx))\n",
    "\n",
    "def show_datum(image, flow, label=None):\n",
    "    # First frame\n",
    "    im1 = _reshape_im(image[:3])\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(im1)\n",
    "    plt.axis('off')\n",
    "    plt.text(-10, -10, 'frame1')\n",
    "    \n",
    "    if label is not None:\n",
    "        if label.ndim == 1:\n",
    "            coords = _label_to_coords(label)\n",
    "        else:\n",
    "            coords = label\n",
    "        first_coords = coords[:len(coords)//2]\n",
    "        _plot_coords(first_coords)\n",
    "    \n",
    "    # Second frame\n",
    "    im2 = _reshape_im(image[3:6])\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(im2)\n",
    "    plt.axis('off')\n",
    "    plt.text(-10, -10, 'frame2')\n",
    "    \n",
    "    if label is not None:\n",
    "        second_coords = coords[len(coords)//2:]\n",
    "        _plot_coords(second_coords)\n",
    "    \n",
    "    # Optical flow\n",
    "    if flow is not None:\n",
    "        im_flow = _vis_flow(flow)\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(im_flow)\n",
    "        plt.axis('off')\n",
    "        plt.text(-10, -10, 'flow')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def get_joints(fp, index, ds_order=('left', 'right', 'head')):\n",
    "    class_num = np.argmax(fp['class'][index])\n",
    "    ds_name = ds_order[(class_num-1)%3]\n",
    "    return fp[ds_name][index]\n",
    "\n",
    "for i in np.random.permutation(len(train_images))[:0]:\n",
    "    # Just visualise the input data so that I know I'm writing it out correctly\n",
    "    print 'Training ground truth (NOT prediction)', i\n",
    "    j = get_joints(train_h5, i)\n",
    "    show_datum(train_images[i], train_flow[i], j)\n",
    "    for ds in ('left', 'right', 'head'):\n",
    "        jx = train_h5[ds][i]\n",
    "        print('{}: {}'.format(ds, jx))\n",
    "    print('Class: {}'.format(train_h5['class'][i]))\n",
    "    \n",
    "for i in np.random.permutation(len(train_neg_images))[:5]:\n",
    "    # Just visualise the input data so that I know I'm writing it out correctly\n",
    "    print 'Training negative', i\n",
    "    show_datum(train_neg_images[i], train_neg_flow[i])\n",
    "    for ds in ('left', 'right', 'head'):\n",
    "        jx = train_neg_h5[ds][i]\n",
    "        print(jx.shape)\n",
    "    print('Class: {}'.format(train_neg_h5['class'][i]))\n",
    "\n",
    "train_centroid_classes = train_h5['poselet']\n",
    "train_centroids = get_centroids(train_centroid_classes[:], centroids)\n",
    "for i in np.random.permutation(len(train_images))[:5]:\n",
    "    print 'Training ground truth poselet (NOT prediction)', i\n",
    "    cls, pslt, coords = train_centroids[i]\n",
    "    show_datum(train_images[i], train_flow[i], coords)\n",
    "    true_cls = np.argmax(train_h5['class'][i])\n",
    "    assert true_cls == cls, '%i (true) vs. %i (from gc)' % (true_cls, cls)\n",
    "    print('Class: {}, poselet: {}\\n\\n\\n'.format(true_cls, pslt))\n",
    "\n",
    "for i in np.random.permutation(len(val_neg_images))[:50]:\n",
    "    print 'Validation negative', i\n",
    "    show_datum(val_neg_images[i], val_neg_flow[i])\n",
    "    for ds in ('left', 'right', 'head'):\n",
    "        jx = val_neg_h5[ds][i]\n",
    "        print(jx.shape)\n",
    "    print('Class: {}'.format(val_neg_h5['class'][i]))\n",
    "\n",
    "val_centroid_classes = val_h5['poselet']\n",
    "val_centroids = get_centroids(val_centroid_classes[:], centroids)\n",
    "for i in np.random.permutation(len(val_images))[:100]:\n",
    "    print 'Validation ground truth (NOT prediction)', i\n",
    "    cls, pslt, coords = val_centroids[i]\n",
    "    show_datum(val_images[i], val_flow[i], coords)\n",
    "    true_cls = np.argmax(val_h5['class'][i])\n",
    "    assert true_cls == cls, '%i (true) vs. %i (from gc)' % (true_cls, cls)\n",
    "    print('Class: {}, poselet: {}\\n\\n\\n'.format(true_cls, pslt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint regressor results\n",
    "\n",
    "This regressor takes in both flow and RGB data, pushes them through different streams, then outputs predictions for each of 3 poselets, along with a confidence for which poselet is in the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try evaluating the CNN on some of our training and evaluation data, just to see whether it's learning anything useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_on_datum(data, model):\n",
    "    batch_size = 64\n",
    "    mps = train.read_mean_pixels('../cache/mean_pixel.mat')\n",
    "    rv = None\n",
    "    # We're manually handling batches because this way we can deal with\n",
    "    # mean pixel subtraction as we go. This is important for HDF5 files\n",
    "    # which we can't fit into memory all at once (and hence need to perform\n",
    "    # iterative mean subtraction on).\n",
    "    dataset_len = len(data[data.keys()[0]])\n",
    "    for start_idx in xrange(0, dataset_len, batch_size):\n",
    "        print('Evaluating on batch {}'.format(start_idx / batch_size + 1))\n",
    "        this_batch = {}\n",
    "        for k in data.keys():\n",
    "            this_batch[k] = data[k][start_idx:start_idx+batch_size]\n",
    "        batch_data = train.sub_mean_pixels(mps, this_batch)\n",
    "        preds = model.predict(batch_data, batch_size=batch_size)\n",
    "        if rv is None:\n",
    "            rv = preds\n",
    "        else:\n",
    "            assert set(rv.keys()) == set(preds.keys())\n",
    "            for k in rv:\n",
    "                rv[k] = np.concatenate((rv[k], preds[k]), axis=0)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_random_samples(images, flow, true_classes, num_samples, title='Sample'):\n",
    "    for i in np.random.permutation(len(images))[:num_samples]:\n",
    "        print('\\n\\n\\n{} {}'.format(title, i))\n",
    "        \n",
    "        # Evaluate\n",
    "        preds = evaluate_on_datum({\n",
    "            'images': images[i:i+1], 'flow': flow[i:i+1]\n",
    "        }, model)\n",
    "        \n",
    "        # Get class info\n",
    "        class_names = ('background', 'left', 'right', 'head')\n",
    "        tc_idx = np.argmax(true_classes[i])\n",
    "        out_probs = preds['class'][0]\n",
    "        pc_idx = np.argmax(preds['class'][0])\n",
    "        pc_prob = out_probs[pc_idx] * 100\n",
    "        print('Class confidences: {}'.format(preds['class'][0]))\n",
    "        print('True class: {}; Predicted class: {} ({}%)'.format(\n",
    "                class_names[tc_idx],\n",
    "                class_names[pc_idx], pc_prob\n",
    "        ))\n",
    "        print(u'\\u2713 Correct class' if pc_idx == tc_idx\n",
    "              else u'\\u2717 Incorrect class')\n",
    "        \n",
    "        # Visualise\n",
    "        if tc_idx > 0:\n",
    "            label = preds[class_names[tc_idx]]\n",
    "        else:\n",
    "            label = None\n",
    "        show_datum(images[i], flow[i], label=label)\n",
    "        \n",
    "        # Get error\n",
    "        # pos_mask = true_classes[i].astype('bool')\n",
    "        # cross_entropy = -np.log(out_probs[pos_mask]).sum() - np.log(out_probs[~pos_mask]).sum()\n",
    "        # tc_name = class_names[tc_idx]\n",
    "        # l1_dist = preds[class_names[tc_idx]]\n",
    "\n",
    "print('# Validation images')\n",
    "evaluate_random_samples(val_images, val_flow, val_h5['class'], 100, title='Validation datum')\n",
    "    \n",
    "print('\\n\\n\\n# Training images')\n",
    "evaluate_random_samples(train_images, train_flow, train_h5['class'], 100, title='Training datum')\n",
    "\n",
    "# These are much less interesting because the classifier is good at picking out background patches.t\n",
    "print('\\n\\n\\n# Validation negatives')\n",
    "evaluate_random_samples(val_neg_images, val_neg_flow, val_neg_h5['class'], 20, title='Validation negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results from poselet classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_random_poselet_scrapes(images, flow, true_pslts, centroids, num_samples, title='Sample'):\n",
    "    for i in np.random.permutation(len(images))[:num_samples]:\n",
    "        print('\\n\\n\\n{} {}'.format(title, i))\n",
    "        preds = evaluate_on_datum({\n",
    "            'images': images[i:i+1], 'flow': flow[i:i+1]\n",
    "        }, poselet_model)\n",
    "        \n",
    "        # Get class info\n",
    "        class_names = ('background', 'left', 'right', 'head')\n",
    "        true_cls, true_pslt, true_coords = get_centroids(true_pslts[i:i+1], centroids)[0]\n",
    "        pred_cls, pred_pslt, pred_coords = get_centroids(preds['poselet'][0:1], centroids)[0]\n",
    "        print('Max confidence: {}'.format(preds['poselet'][0].max()))\n",
    "        print(u'{} True class: {}; Predicted class: {}'.format(\n",
    "                u'\\u2713' if true_cls == pred_cls else u'\\u2717',\n",
    "                class_names[true_cls],\n",
    "                class_names[pred_cls],\n",
    "        ))\n",
    "        print(u'{} True poselet: {}; Predicted poselet: {}'.format(\n",
    "                u'\\u2713' if true_cls == pred_cls and true_pslt == pred_pslt else u'\\u2717',\n",
    "                true_pslt,\n",
    "                pred_pslt,\n",
    "        ))\n",
    "        \n",
    "        # Visualise\n",
    "        if pred_cls > 0:\n",
    "            label = centroids[pred_cls-1][pred_pslt]\n",
    "        else:\n",
    "            label = None\n",
    "        show_datum(images[i], flow[i], label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_random_poselet_scrapes(train_images, train_flow, train_h5['poselet'], centroids, 150, 'Train sample')\n",
    "evaluate_random_poselet_scrapes(val_images, val_flow, val_h5['poselet'], centroids, 150, 'Validation sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between poselet and regressor methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Predictions = namedtuple('Predictions', ['type', 'results', 'classes', 'coords'])\n",
    "\n",
    "def get_all_evaluations_poselet(images, flow, centroids):\n",
    "    print('Beginning poselet evaluation')\n",
    "    all_evaluations = evaluate_on_datum({'images': images, 'flow': flow}, poselet_model)\n",
    "    cls_pslt_coord_tuples = get_centroids(all_evaluations['poselet'], centroids)\n",
    "    poselet_coords = [t[2] for t in cls_pslt_coord_tuples]\n",
    "    classes = np.array([t[0] for t in cls_pslt_coord_tuples])\n",
    "    return Predictions(\n",
    "        type='poselet', results=all_evaluations, classes=classes, coords=poselet_coords\n",
    "    )\n",
    "\n",
    "def get_all_evaluations_regressor(images, flow):\n",
    "    print('Beginning regressor evaluation')\n",
    "    all_evaluations = evaluate_on_datum({'images': images, 'flow': flow}, model)\n",
    "    classes = np.argmax(all_evaluations['class'], axis=1)\n",
    "    true_coords = []\n",
    "    for idx, cls in enumerate(classes):\n",
    "        if cls == 0:\n",
    "            coord = None\n",
    "        else:\n",
    "            ds_name = ('left', 'right', 'head')[cls-1]\n",
    "            coord = _label_to_coords(all_evaluations[ds_name][idx])\n",
    "        true_coords.append(coord)\n",
    "    return Predictions(\n",
    "        type='regressor', results=all_evaluations, classes=classes, coords=true_coords\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poselet_evals = get_all_evaluations_poselet(val_images, val_flow, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../cache/poselet_model_preds-30k-instead-of-14k.pickle', 'wb') as fp:\n",
    "    cPickle.dump(poselet_evals, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor_evals = get_all_evaluations_regressor(val_images, val_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../cache/regressor_model_preds.pickle', 'wb') as fp:\n",
    "    cPickle.dump(regressor_evals, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative comparison measures\n",
    "\n",
    "A brief explanation of each of the measures used below:\n",
    "\n",
    "- Classification accuracy is $\\frac{\\text{correct classifications}}{\\text{total classifications}}$ for the sub-pose class task (so predicting whether patch is background/left/right/head).\n",
    "- Class split indicates what fraction of the predictions and training set are of which sub-pose class. This is good for detecting bias.\n",
    "- MAE is calculated for each sub-pose $j$ as $\\frac{1}{N} \\sum_{n=1}^N \\mathbf 1(C_n = \\hat C_n) \\|\\vec x_n^{(j)} - \\hat x^{(j)}_n\\|_1$ (where $C_n$ is the class of sample $n$, $\\vec x_n^{(j)}$ denotes the locations for the joints in sub-pose $j$ in sample $n$, and the hat is used to denote predictions); this does not penalise incorrectly classified sub-poses.\n",
    "- The PCP metric is just like normal strict PCP, except all joints in incorrectly classified sub-poses are considered incorrect.\n",
    "  - Some \"limbs\" are totally made up here. For instance, the \"{l, r}shol{1, 2}\" limbs actually measure correspond to a line between the relevant shoulder and the chin, whilst the \"head{1, 2}\" limbs measure chin-to-top-of-head distance. \"{l, r}hand{1, 2}\" is another made-up one corresponding to the distance between a point at the bottom of the forearm and another on the hand. The PCPs for these should be taken with a grain of salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete list of indices giving the endpoints of limbs,\n",
    "# arranged in a dictionary according to which sub-pose the\n",
    "# limbs belong to. Used for PCP calculations.\n",
    "limbs = {\n",
    "    'left': {\n",
    "        'indices': [\n",
    "            # First frame\n",
    "            (0, 1),\n",
    "            (1, 2),\n",
    "            (2, 3),\n",
    "            # Second frame\n",
    "            (4, 5),\n",
    "            (5, 6),\n",
    "            (6, 7)\n",
    "        ],\n",
    "        'names': [\n",
    "            'luarm1',\n",
    "            'lfarm1',\n",
    "            'lhand1',\n",
    "            'luarm2',\n",
    "            'lfarm2',\n",
    "            'lhand2',\n",
    "        ],\n",
    "        'partnames': [\n",
    "            'lhand1',\n",
    "            'lwrist1',\n",
    "            'lelb1',\n",
    "            'lshol1',\n",
    "            'lhand2',\n",
    "            'lwrist2',\n",
    "            'lelb2',\n",
    "            'lshol2'\n",
    "        ]\n",
    "    },\n",
    "    'right': {\n",
    "        'indices': [\n",
    "            # First frame\n",
    "            (0, 1),\n",
    "            (1, 2),\n",
    "            (2, 3),\n",
    "            # Second frame\n",
    "            (4, 5),\n",
    "            (5, 6),\n",
    "            (6, 7)\n",
    "        ],\n",
    "        'names': [\n",
    "            'ruarm1',\n",
    "            'rfarm1',\n",
    "            'rhand1',\n",
    "            'ruarm2',\n",
    "            'rfarm2',\n",
    "            'rhand2',\n",
    "        ],\n",
    "        'partnames': [\n",
    "            'rhand1',\n",
    "            'rwrist1',\n",
    "            'relb1',\n",
    "            'rshol1',\n",
    "            'rhand2',\n",
    "            'rwrist2',\n",
    "            'relb2',\n",
    "            'rshol2'\n",
    "        ]\n",
    "    },\n",
    "    'head': {\n",
    "        'indices': [\n",
    "            # First frame\n",
    "            (0, 3),\n",
    "            (1, 3),\n",
    "            (2, 3),\n",
    "            # Second frame\n",
    "            (4, 7),\n",
    "            (5, 7),\n",
    "            (6, 7),\n",
    "        ],\n",
    "        'names': [\n",
    "            'rshol1',\n",
    "            'lshol1',\n",
    "            'head1',\n",
    "            'rshol2',\n",
    "            'lshol2',\n",
    "            'head2',\n",
    "        ],\n",
    "        'partnames': [\n",
    "            'rshol1',\n",
    "            'lshol1',\n",
    "            'head1',\n",
    "            'chin1',\n",
    "            'rshol2',\n",
    "            'lshol2',\n",
    "            'head2',\n",
    "            'chin2',\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "_lr_12 = [(s, str(f)) for s in ('l', 'r') for f in 1, 2]\n",
    "_avg_names = lambda n: (n, {s + n + f for s, f in _lr_12})\n",
    "\n",
    "# Equivalent limbs for the purposes of PCP calculation (can average PCP)\n",
    "pcps_to_average = [\n",
    "    _avg_names('hand'),\n",
    "    _avg_names('uarm'),\n",
    "    _avg_names('farm'),\n",
    "    _avg_names('shol'),\n",
    "    ('head', {'head1', 'head2'})\n",
    "]\n",
    "\n",
    "# Equivalent parts for the purposes of accuracy calculations (can combine accuracies)\n",
    "equiv_parts = [\n",
    "    _avg_names('shol'),\n",
    "    _avg_names('elb'),\n",
    "    _avg_names('wrist'),\n",
    "    _avg_names('hand'),\n",
    "    ('head', {'head1', 'head2'}),\n",
    "    ('chin', {'chin1', 'chin2'})\n",
    "]\n",
    "# Now we can invert equiv_parts to map part names to combined part names\n",
    "aggregate_part_table = {}\n",
    "for agg_name, partname_set in equiv_parts:\n",
    "    for partname in partname_set:\n",
    "        aggregate_part_table[partname] = agg_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_acc(thresholds, accs_dict, plot_title):\n",
    "    for label, acc in accs_dict.iteritems():\n",
    "        plt.plot(thresholds, acc, label=label)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlim((min(thresholds), max(thresholds)))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('threshold (px)')\n",
    "    plt.title(plot_title)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# test_in_vals = np.linspace(0, 50, 100)\n",
    "# plot_acc(test_in_vals, -1 / (test_in_vals + 1) + 1, 'Example plot', 'foo')\n",
    "\n",
    "def get_classification_acc(true_class_nums, pred_class_nums):\n",
    "    assert true_class_nums.shape == pred_class_nums.shape\n",
    "    assert true_class_nums.ndim == 1\n",
    "    return (pred_class_nums == true_class_nums).sum() / float(len(true_class_nums))\n",
    "\n",
    "def get_class_split(class_nums, num_classes):\n",
    "    rv = np.zeros((num_classes,))\n",
    "    total = float(len(class_nums))\n",
    "    for i in xrange(num_classes):\n",
    "        rv[i] = (class_nums == i).sum() / total\n",
    "    return rv\n",
    "\n",
    "def get_reg_mae(ground_truth, predictions, class_names=(None, 'left', 'right', 'head')):\n",
    "    num_classes = len(class_names)\n",
    "    rv = np.zeros((num_classes,))\n",
    "    gt_class_nums = np.argmax(ground_truth['class'][:], axis=1)\n",
    "    pred_class_nums = predictions.classes\n",
    "    \n",
    "    for i in xrange(num_classes):\n",
    "        if i == 0:\n",
    "            # This is the background class, so there are no regressor outputs\n",
    "            rv[i] = 0\n",
    "            continue\n",
    "            \n",
    "        class_mask = (gt_class_nums == i) & (gt_class_nums == pred_class_nums)\n",
    "        cls_name = class_names[i]\n",
    "        assert cls_name is not None\n",
    "        true_locs = _label_to_coords(ground_truth[cls_name][class_mask, :])\n",
    "        pred_locs_lists = np.array(predictions.coords)[class_mask]\n",
    "        pred_locs = np.array(pred_locs_lists.tolist(), dtype='float')\n",
    "        num_samples = float(class_mask.sum())\n",
    "        rv[i] = np.abs(true_locs - pred_locs).sum() / num_samples\n",
    "        \n",
    "    return rv\n",
    "\n",
    "def get_all_pcps(ground_truth, predictions, limbs=limbs):\n",
    "    # use evaluation.score_predictions_pcp(gt_joints, predictions, limbs)\n",
    "    all_pcps = {}\n",
    "    subpose_indices = {\n",
    "        'left': 1,\n",
    "        'right': 2,\n",
    "        'head': 3\n",
    "    }\n",
    "    \n",
    "    for subpose_name in limbs:\n",
    "        names = limbs[subpose_name]['names']\n",
    "        assert set(names).isdisjoint(set(all_pcps.keys())), \\\n",
    "            \"Duplicate names detected\"\n",
    "        indices = limbs[subpose_name]['indices']\n",
    "            \n",
    "        # Next calculate accuracy and a mask to select only predictions which\n",
    "        # are correct. We will feed the PCP calculator only correctly\n",
    "        # classified poses, but we will then multiply the returned PCP\n",
    "        # values by the accuracy to account for the incorrect poses.\n",
    "        gt_classes = np.argmax(ground_truth['class'][:], axis=1)\n",
    "        pred_classes = predictions.classes\n",
    "        class_num = subpose_indices[subpose_name]\n",
    "        pos_samples = float((gt_classes == class_num).sum())\n",
    "        correct_mask = (gt_classes == class_num) & (pred_classes == class_num)\n",
    "        accuracy = correct_mask.sum() / pos_samples\n",
    "        \n",
    "        gt_joints = _label_to_coords(ground_truth[subpose_name][correct_mask, ...])\n",
    "        masked_pred_joints = np.array(predictions.coords)[correct_mask, ...]\n",
    "        pred_joints = np.array(masked_pred_joints.tolist())\n",
    "        assert gt_joints.shape == pred_joints.shape\n",
    "        subpose_pcps = evaluate.score_predictions_pcp(\n",
    "            gt_joints, pred_joints, indices\n",
    "        )\n",
    "        assert len(subpose_pcps) == len(names)\n",
    "        named_subpose_pcps = dict(zip(names, (accuracy * p for p in subpose_pcps)))\n",
    "        all_pcps.update(named_subpose_pcps)\n",
    "        \n",
    "    return all_pcps\n",
    "\n",
    "def show_pcp(pcp_dict):\n",
    "    sorted_items = sorted(pcp_dict.items())\n",
    "    print('name' + ''.join('{:>10}'.format(l) for l, _ in sorted_items))\n",
    "    print('pcp ' + ''.join('{:>10.4f}'.format(v) for _, v in sorted_items))\n",
    "    \n",
    "def per_class_show(values, classes=('bkgnd', 'left', 'right', 'head')):\n",
    "    return ', '.join('{:>5}: {:>7.3f}'.format(c, v) for c, v in zip(classes, values))\n",
    "    return rv\n",
    "\n",
    "def get_all_accs(ground_truth, predictions, thresholds):\n",
    "    all_accs = {}\n",
    "    # TODO: subpose_indices should be factored out, since it's also used in get_all_pcps\n",
    "    subpose_indices = {\n",
    "        'left': 1,\n",
    "        'right': 2,\n",
    "        'head': 3\n",
    "    }\n",
    "    \n",
    "    for subpose_name in limbs:\n",
    "        part_names = limbs[subpose_name]['partnames']\n",
    "        indices = limbs[subpose_name]['indices']\n",
    "            \n",
    "        # We need a class mask just like we used for the PCP detector\n",
    "        gt_classes = np.argmax(ground_truth['class'][:], axis=1)\n",
    "        pred_classes = predictions.classes\n",
    "        class_num = subpose_indices[subpose_name]\n",
    "        pos_samples = float((gt_classes == class_num).sum())\n",
    "        correct_mask = (gt_classes == class_num) & (pred_classes == class_num)\n",
    "        accuracy = correct_mask.sum() / pos_samples\n",
    "        \n",
    "        gt_joints = _label_to_coords(ground_truth[subpose_name][correct_mask, ...])\n",
    "        masked_pred_joints = np.array(predictions.coords)[correct_mask, ...]\n",
    "        pred_joints = np.array(masked_pred_joints.tolist())\n",
    "        subpose_accs = np.vstack(evaluate.score_predictions_acc(\n",
    "            gt_joints, pred_joints, thresholds\n",
    "        )).T\n",
    "        # Make sure that we collect all relevant accuracies for each part, then\n",
    "        # average over them later.\n",
    "        assert len(part_names) == len(subpose_accs)\n",
    "        for part_name, accs in zip(part_names, subpose_accs):\n",
    "            agg_pn = aggregate_part_table.get(part_name, part_name)\n",
    "            true_acc = accuracy * accs\n",
    "            all_accs.setdefault(agg_pn, []).append(true_acc)\n",
    "    \n",
    "    combined_accs = {}\n",
    "    for part_name, accs_list in all_accs.iteritems():\n",
    "        combined_accs[part_name] = np.mean(accs_list, axis=0)\n",
    "        \n",
    "    return combined_accs\n",
    "\n",
    "def average_pcps(pcp_dict, to_average):\n",
    "    removed_keys = set().union(*(s for n, s in to_average))\n",
    "    rv = {\n",
    "        k: v for k, v in pcp_dict.iteritems() if k not in removed_keys\n",
    "    }\n",
    "    for combined_name, components in to_average:\n",
    "        rv[combined_name] = np.mean([pcp_dict[k] for k in components])\n",
    "    return rv\n",
    "    \n",
    "def print_evaluation_summary(ground_truth, predictions):\n",
    "    assert {'class', 'left', 'right', 'head'}.issubset(set(ground_truth.keys()))\n",
    "    \n",
    "    # Classification accuracy\n",
    "    class_nums = np.argmax(ground_truth['class'][:], axis=1)\n",
    "    class_acc = get_classification_acc(class_nums, predictions.classes)\n",
    "    \n",
    "    # Comparison of class split\n",
    "    pred_class_split = get_class_split(predictions.classes, 4)\n",
    "    true_class_split = get_class_split(class_nums, 4)\n",
    "    \n",
    "    # Regressor MAE\n",
    "    reg_mae = get_reg_mae(ground_truth, predictions)\n",
    "    \n",
    "    # PCP\n",
    "    pcp_dict = get_all_pcps(ground_truth, predictions)\n",
    "    \n",
    "    # Accuracy (variable pixel threshold)\n",
    "    thresholds = np.linspace(0, 80, 80)\n",
    "    accs_dict = get_all_accs(ground_truth, predictions, thresholds)\n",
    "    \n",
    "    # Display everything\n",
    "    print('Evaluation summary for {} model'.format(predictions.type))\n",
    "    print(\n",
    "        'Classifier accuracy: {}\\n'\n",
    "        'Class split in predictions: {}\\n'\n",
    "        'Class split in training ground truths: {}\\n'\n",
    "        'MAE for correct classifications: {}\\n'\n",
    "        'PCPs (class-sensitive):'.format(\n",
    "            class_acc, per_class_show(pred_class_split),\n",
    "            per_class_show(true_class_split),\n",
    "            per_class_show(reg_mae)\n",
    "    ))\n",
    "    show_pcp(average_pcps(pcp_dict, pcps_to_average))\n",
    "    plot_acc(thresholds, accs_dict, 'Accuracies ({})'.format(predictions.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_gt = {\n",
    "    'left': val_h5['left'],\n",
    "    'right': val_h5['right'],\n",
    "    'head': val_h5['head'],\n",
    "    'class': val_h5['class']\n",
    "}\n",
    "\n",
    "print_evaluation_summary(val_gt, poselet_evals)\n",
    "print_evaluation_summary(val_gt, regressor_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def poselet_weighted_average(poselet_model_results, centroids=centroids, num_subposes=3):\n",
    "    \"\"\"Instead of picking the highest-scoring poselet\n",
    "    and returning the centroid of that, we take a \n",
    "    weighted average of poselets that have the same\n",
    "    class. Hopefully this produces better results.\"\"\"\n",
    "    poselet_probs = poselet_model_results['poselet']\n",
    "    ppc = (poselet_probs.shape[1] - 1) / num_subposes\n",
    "    num_classes = num_subposes + 1\n",
    "    class_probs = np.zeros((len(poselet_probs), num_classes))\n",
    "    class_probs[:, 0] = poselet_probs[:, 0]\n",
    "    \n",
    "    all_weighted_means = []\n",
    "    \n",
    "    for subpose_num in xrange(num_subposes):\n",
    "        start_idx = subpose_num * ppc + 1\n",
    "        end_idx = start_idx + ppc\n",
    "        \n",
    "        # Start by figuring out the probability that this subpose is the correct one\n",
    "        subpose_probs = np.sum(\n",
    "            poselet_probs[:, start_idx:end_idx], axis=1\n",
    "        )\n",
    "        class_probs[:, subpose_num+1] = subpose_probs\n",
    "        \n",
    "        # Now get poselet probs and find joint locations by taking expectation of\n",
    "        # centroids.\n",
    "        sp_centroids = centroids[subpose_num]\n",
    "        # XXX: What if subpose_probs is 0 somewhere? Should probably just make the\n",
    "        # numerator zero, since if subpose_probs[i] is 0 then the given subpose\n",
    "        # is almost certainly not in sample i.\n",
    "        norm_probs = poselet_probs[:, start_idx:end_idx] / subpose_probs[:, np.newaxis]\n",
    "        norm_probs = np.nan_to_num(norm_probs)\n",
    "        # Make sure all of our probabilities are normalised\n",
    "        assert (np.abs(norm_probs.sum(axis=1) - 1) < 0.01).all()\n",
    "        \n",
    "        # Let N be the number of samples and P be the number of poselets.\n",
    "        # We now have an N*P array of probabilities and a P*J array of centroids.\n",
    "        # What we want is an N*J array of means. Broadcasting to the rescue!\n",
    "        centroids_bc = sp_centroids[np.newaxis, :, :]\n",
    "        pprobs_bc = norm_probs[:, :, np.newaxis]\n",
    "        # 'combined' should be N*P*J\n",
    "        combined = centroids_bc * pprobs_bc\n",
    "        assert combined.shape == norm_probs.shape + sp_centroids.shape[1:]\n",
    "        true_means = np.sum(combined, axis=1)\n",
    "        assert true_means.shape == (len(poselet_probs), sp_centroids.shape[1])\n",
    "        \n",
    "        all_weighted_means.append(true_means)\n",
    "        \n",
    "    # Select only the weighted means corresponding to the best class\n",
    "    class_nums = np.argmax(class_probs, axis=1)\n",
    "    np_awm = np.array(all_weighted_means)\n",
    "    num_samples = len(poselet_probs)\n",
    "    best_coords = np.ndarray((num_samples,), dtype='object')\n",
    "    best_coords[class_nums == 0] = None\n",
    "    \n",
    "    for subpose_num in xrange(num_subposes):\n",
    "        mask = class_nums == subpose_num + 1\n",
    "        # We prepend None and drop it again so that numpy gives us a\n",
    "        # 1D object array, each entry of which is a JD float array giving\n",
    "        # joint coordinates. If we don't do this then Numpy gives us a\n",
    "        # 2D array which doesn't play nice with our 1D return value\n",
    "        # array.\n",
    "        label_slice = np_awm[subpose_num, mask, ...]\n",
    "        coord_slice = _label_to_coords(label_slice)\n",
    "        best_coords[mask] = np.array([None] + list(coord_slice))[1:]\n",
    "    \n",
    "    return Predictions(\n",
    "        type='weighted poselet', results=poselet_model_results,\n",
    "        classes=class_nums, coords=list(best_coords)\n",
    "    )\n",
    "\n",
    "weighted_average_preds = poselet_weighted_average(poselet_evals.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Yep, classification error goes down too because now I'm marginalising\n",
    "# over poselets properly to find the right subpose class (thought I was\n",
    "# doing that before, but it turned out that I wasn't)\n",
    "print_evaluation_summary(val_gt, weighted_average_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
