{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to test the following hypothesis: my resnet is learning to predict subpose correctly, but is only predicting biposelets by relying on irrelevant cues present in the training set (i.e. overfitting to biposelets, but not necessarily to subposes). Skip to the \"interesting stuff starts here\" heading for actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import h5py\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "from os import path\n",
    "\n",
    "import train\n",
    "import evaluate\n",
    "from train import infer_sizes\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data and get a model\n",
    "no_preds = False\n",
    "dest_dir = '/home/sam/delete-me/resnet-preds/'\n",
    "cache_dir = '../cache/mpii-cooking/'\n",
    "train_h5_path = path.join(cache_dir, 'train-patches/samples-000001.h5')\n",
    "train_neg_h5_path = path.join(cache_dir, 'train-patches/negatives.h5')\n",
    "val_h5_path = path.join(cache_dir, 'val-patches/samples-000001.h5')\n",
    "val_neg_h5_path = path.join(cache_dir, 'val-patches/negatives.h5')\n",
    "train_h5 = h5py.File(train_h5_path, 'r')\n",
    "train_neg_h5 = h5py.File(train_neg_h5_path, 'r')\n",
    "val_h5 = h5py.File(val_h5_path, 'r')\n",
    "val_neg_h5 = h5py.File(val_neg_h5_path, 'r')\n",
    "train_images, train_flow = train_h5['images'], train_h5['flow']\n",
    "train_neg_images, train_neg_flow = train_neg_h5['images'], train_neg_h5['flow']\n",
    "val_images, val_flow = val_h5['images'], val_h5['flow']\n",
    "val_neg_images, val_neg_flow = val_neg_h5['images'], val_neg_h5['flow']\n",
    "ds_shape = infer_sizes(train_h5_path)\n",
    "mp_path = '../cache/mpii-cooking/mean_pixel.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding input layers\n",
      "Adding block of 64 channels (from None channels)\n",
      "Adding block of 64 channels (from 64 channels)\n",
      "Adding block of 64 channels (from 64 channels)\n",
      "Adding block of 128 channels (from 64 channels)\n",
      "Adding block of 128 channels (from 128 channels)\n",
      "Adding block of 128 channels (from 128 channels)\n",
      "Adding block of 128 channels (from 128 channels)\n",
      "Adding block of 256 channels (from 128 channels)\n",
      "Adding block of 256 channels (from 256 channels)\n",
      "Adding block of 256 channels (from 256 channels)\n",
      "Adding block of 256 channels (from 256 channels)\n",
      "Adding block of 256 channels (from 256 channels)\n",
      "Adding block of 256 channels (from 256 channels)\n",
      "Adding block of 512 channels (from 256 channels)\n",
      "Adding block of 512 channels (from 512 channels)\n",
      "Adding block of 512 channels (from 512 channels)\n",
      "Adding pool and flatten layers\n",
      "Adding final layers\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.0001, nesterov=True, momentum=0.9)\n",
    "poselet_model = models.resnet34_poselet_class(ds_shape, sgd, 'glorot_normal')\n",
    "poselet_model.load_weights('../cache/mpii-cooking/keras-checkpoints-resnet-from-3582/checkpoints/model-iter-23808-r604131.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate = reload(evaluate)\n",
    "def test_on_data(images, batch_size=32, model=poselet_model, mp_path=mp_path):\n",
    "    \"\"\"Test on an HDF5 file of training or validation data.\n",
    "    Return a matrix with each row giving the predicted output\n",
    "    distribution.\"\"\"\n",
    "    return evaluate.get_predictions(model, mp_path, {'images': images}, batch_size)\n",
    "\n",
    "def save_preds(preds, dest_name):\n",
    "    assert len(preds.keys()) == 1 and 'poselet' in preds.keys()\n",
    "    dest_file = path.join(dest_dir, dest_name + '.npy')\n",
    "    np.save(dest_file, preds['poselet'])\n",
    "    print('Saved to ' + dest_file)\n",
    "\n",
    "def load_preds(dest_name):\n",
    "    dest_file = path.join(dest_dir, dest_name + '.npy')\n",
    "    return np.load(dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if no_preds:\n",
    "    val_neg_preds = test_on_data(val_neg_images)\n",
    "    save_preds(val_neg_preds, 'val_neg_preds')\n",
    "\n",
    "    val_preds = test_on_data(val_images)\n",
    "    save_preds(val_preds, 'val_preds')\n",
    "\n",
    "    train_neg_preds = test_on_data(train_neg_images)\n",
    "    save_preds(train_neg_preds, 'train_neg_preds')\n",
    "\n",
    "    train_preds = test_on_data(train_images)\n",
    "    save_preds(train_preds, 'train_preds')\n",
    "else:\n",
    "    val_neg_preds = load_preds('val_neg_preds')\n",
    "    val_preds = load_preds('val_preds')\n",
    "    train_neg_preds = load_preds('train_neg_preds')\n",
    "    train_preds = load_preds('train_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_neg_gt = np.array(val_neg_h5['poselet']).astype('float32')\n",
    "val_gt = np.array(val_h5['poselet']).astype('float32')\n",
    "train_neg_gt = np.array(train_neg_h5['poselet']).astype('float32')\n",
    "train_gt = np.array(train_h5['poselet']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2409, 901), (14454, 901))\n",
      "(16863, 901)\n"
     ]
    }
   ],
   "source": [
    "print(val_neg_gt.shape, val_gt.shape)\n",
    "all_val_preds = np.concatenate((val_preds, val_neg_preds))\n",
    "all_train_preds = np.concatenate((train_preds, train_neg_preds))\n",
    "all_val_gt = np.concatenate((val_gt, val_neg_gt))\n",
    "all_train_gt = np.concatenate((train_gt, train_neg_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_names=('bg', 'shols', 'luarm', 'lmarm', 'llarm', 'lhand', 'ruarm', 'rmarm', 'rlarm', 'rhand')\n",
    "\n",
    "# From http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def eval_sp(gt_bp_dist, pred_bp_dist):\n",
    "    gt_bp_labels = argmax_preds(gt_bp_dist)\n",
    "    pred_bp_labels = argmax_preds(pred_bp_dist)\n",
    "    print('Biposelet accuracy: %.4f' % skmetrics.accuracy_score(gt_bp_labels, pred_bp_labels))\n",
    "    \n",
    "    entropies = entropy(pred_bp_dist.T, base=2)\n",
    "    # Make sure that we did that over the right axis\n",
    "    assert entropies.ndim == 1 and len(entropies) == pred_bp_dist.shape[0]\n",
    "    print(u'Prediction entropy: %.2f bits (+- %.2f)' % (entropies.mean(), entropies.std()))\n",
    "    print('Uniform entropy would be %.2f bits' % entropy(np.ones((pred_bp_dist.shape[1],)) / pred_bp_dist.shape[1], base=2))\n",
    "\n",
    "def vis_label_skew(label_mat, title='Label skew'):\n",
    "    max_inds = argmax_preds(label_mat)\n",
    "    _, counts = np.unique(max_inds, return_counts=True)\n",
    "    plt.hist(np.log(counts+1), 20)\n",
    "    plt.xlabel('log(#instances+1)')\n",
    "    plt.ylabel('Classes with that #instances')\n",
    "    plt.title(title)\n",
    "    for i in range(11): print('#classes with <=%i instances: %i' % (i, (counts <= i).sum()))\n",
    "    \n",
    "def evaluate_preds(preds, gts):\n",
    "    # Visualise skew in ground truth and predicted labels\n",
    "    vis_label_skew(preds, title='Predicted label skew')\n",
    "    plt.show()\n",
    "    vis_label_skew(gts, title='True label skew')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualise subpose classification accuracy\n",
    "    sp_marginal_gt, bp_dist_gt = split_preds(gts)\n",
    "    sp_marginal_pred, bp_dist_pred = split_preds(preds)\n",
    "    sp_label_gt = argmax_preds(sp_marginal_gt)\n",
    "    sp_label_pred = argmax_preds(sp_marginal_pred)\n",
    "    matrix = skmetrics.confusion_matrix(sp_label_gt, sp_label_pred)\n",
    "    plot_confusion_matrix(matrix, title='Subpose confusion matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\\nSubpose classification report:')\n",
    "    print(skmetrics.classification_report(sp_label_gt, sp_label_pred, target_names=target_names))\n",
    "    \n",
    "    # Examine biposelet classification accuracy\n",
    "    num_sp = len(bp_dist_gt)\n",
    "    for sp_idx in range(num_sp):\n",
    "        print('\\n\\nWorking on subpose %i/%i (%s)' % (sp_idx+1, num_sp, target_names[sp_idx+1]))\n",
    "        relevant = sp_label_gt == (sp_idx + 1)\n",
    "        eval_sp(bp_dist_gt[sp_idx][relevant, :], bp_dist_pred[sp_idx][relevant, :])\n",
    "\n",
    "def split_preds(preds, num_bp=100):\n",
    "    # Split the preds according to both subpose class (+ background)\n",
    "    # vs. biposelet class\n",
    "    assert preds.ndim == 2\n",
    "    num_sp = int((preds.shape[1] - 1) / num_bp)\n",
    "    assert preds.shape[1] == num_bp * num_sp + 1\n",
    "    subpose_preds = np.zeros((preds.shape[0], num_sp + 1))\n",
    "    biposelet_preds = tuple()\n",
    "    subpose_preds[:, 0] = preds[:, 0]\n",
    "    for sp_idx in range(num_sp):\n",
    "        start_idx = sp_idx * num_bp + 1\n",
    "        end_idx = start_idx + num_bp\n",
    "        this_block = preds[:, start_idx:end_idx]\n",
    "        sums = np.sum(this_block, axis=1)\n",
    "        subpose_preds[:, sp_idx+1] = sums\n",
    "        sums[sums <= 0] = 1\n",
    "        norm_block = this_block / sums.reshape((sums.size, 1))\n",
    "        biposelet_preds += (norm_block,)\n",
    "    return subpose_preds, biposelet_preds\n",
    "\n",
    "def argmax_preds(preds):\n",
    "    # Just compute argmax of predictions matrix\n",
    "    assert preds.ndim == 2\n",
    "    return np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting stuff starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On validation set:\n",
      "#classes with <=0 instances: 0\n",
      "#classes with <=1 instances: 82\n",
      "#classes with <=2 instances: 152\n",
      "#classes with <=3 instances: 218\n",
      "#classes with <=4 instances: 259\n",
      "#classes with <=5 instances: 297\n",
      "#classes with <=6 instances: 335\n",
      "#classes with <=7 instances: 366\n",
      "#classes with <=8 instances: 394\n",
      "#classes with <=9 instances: 419\n",
      "#classes with <=10 instances: 437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#classes with <=0 instances: 0\n",
      "#classes with <=1 instances: 49\n",
      "#classes with <=2 instances: 77\n",
      "#classes with <=3 instances: 115\n",
      "#classes with <=4 instances: 136\n",
      "#classes with <=5 instances: 176\n",
      "#classes with <=6 instances: 203\n",
      "#classes with <=7 instances: 224\n",
      "#classes with <=8 instances: 256\n",
      "#classes with <=9 instances: 279\n",
      "#classes with <=10 instances: 306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Subpose classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         bg       0.41      0.96      0.58      2409\n",
      "      shols       0.77      0.36      0.49      1606\n",
      "      luarm       0.77      0.38      0.51      1606\n",
      "      lmarm       0.95      0.73      0.83      1606\n",
      "      llarm       0.88      0.79      0.83      1606\n",
      "      lhand       0.71      0.79      0.75      1606\n",
      "      ruarm       0.76      0.31      0.44      1606\n",
      "      rmarm       0.93      0.71      0.80      1606\n",
      "      rlarm       0.85      0.79      0.82      1606\n",
      "      rhand       0.67      0.80      0.73      1606\n",
      "\n",
      "avg / total       0.75      0.68      0.67     16863\n",
      "\n",
      "\n",
      "\n",
      "Working on subpose 1/9 (shols)\n",
      "Biposelet accuracy: 0.0722\n",
      "Prediction entropy: 3.79 bits (+- 0.83)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 2/9 (luarm)\n",
      "Biposelet accuracy: 0.0685\n",
      "Prediction entropy: 3.54 bits (+- 0.95)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 3/9 (lmarm)\n",
      "Biposelet accuracy: 0.2136\n",
      "Prediction entropy: 2.68 bits (+- 1.08)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 4/9 (llarm)\n",
      "Biposelet accuracy: 0.3244\n",
      "Prediction entropy: 2.24 bits (+- 0.95)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 5/9 (lhand)\n",
      "Biposelet accuracy: 0.1793\n",
      "Prediction entropy: 2.96 bits (+- 1.07)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 6/9 (ruarm)\n",
      "Biposelet accuracy: 0.0567\n",
      "Prediction entropy: 3.93 bits (+- 0.99)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 7/9 (rmarm)\n",
      "Biposelet accuracy: 0.1762\n",
      "Prediction entropy: 2.75 bits (+- 0.95)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 8/9 (rlarm)\n",
      "Biposelet accuracy: 0.3219\n",
      "Prediction entropy: 2.23 bits (+- 1.08)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 9/9 (rhand)\n",
      "Biposelet accuracy: 0.2528\n",
      "Prediction entropy: 2.79 bits (+- 0.95)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "On training set:\n",
      "#classes with <=0 instances: 0\n",
      "#classes with <=1 instances: 6\n",
      "#classes with <=2 instances: 9\n",
      "#classes with <=3 instances: 9\n",
      "#classes with <=4 instances: 11\n",
      "#classes with <=5 instances: 14\n",
      "#classes with <=6 instances: 16\n",
      "#classes with <=7 instances: 18\n",
      "#classes with <=8 instances: 23\n",
      "#classes with <=9 instances: 25\n",
      "#classes with <=10 instances: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#classes with <=0 instances: 0\n",
      "#classes with <=1 instances: 0\n",
      "#classes with <=2 instances: 0\n",
      "#classes with <=3 instances: 0\n",
      "#classes with <=4 instances: 0\n",
      "#classes with <=5 instances: 0\n",
      "#classes with <=6 instances: 0\n",
      "#classes with <=7 instances: 0\n",
      "#classes with <=8 instances: 0\n",
      "#classes with <=9 instances: 0\n",
      "#classes with <=10 instances: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Subpose classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         bg       1.00      0.99      1.00     38460\n",
      "      shols       0.98      0.99      0.99     25640\n",
      "      luarm       0.97      0.97      0.97     25640\n",
      "      lmarm       0.99      0.98      0.98     25640\n",
      "      llarm       0.97      0.97      0.97     25640\n",
      "      lhand       0.97      0.96      0.96     25640\n",
      "      ruarm       0.97      0.97      0.97     25640\n",
      "      rmarm       0.98      0.99      0.99     25640\n",
      "      rlarm       0.97      0.97      0.97     25640\n",
      "      rhand       0.96      0.96      0.96     25640\n",
      "\n",
      "avg / total       0.98      0.98      0.98    269220\n",
      "\n",
      "\n",
      "\n",
      "Working on subpose 1/9 (shols)\n",
      "Biposelet accuracy: 0.5856\n",
      "Prediction entropy: 2.55 bits (+- 0.65)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 2/9 (luarm)\n",
      "Biposelet accuracy: 0.6298\n",
      "Prediction entropy: 2.19 bits (+- 0.69)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 3/9 (lmarm)\n",
      "Biposelet accuracy: 0.6528\n",
      "Prediction entropy: 1.91 bits (+- 0.69)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 4/9 (llarm)\n",
      "Biposelet accuracy: 0.7141\n",
      "Prediction entropy: 1.70 bits (+- 0.65)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 5/9 (lhand)\n",
      "Biposelet accuracy: 0.5764\n",
      "Prediction entropy: 2.28 bits (+- 0.80)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 6/9 (ruarm)\n",
      "Biposelet accuracy: 0.6142\n",
      "Prediction entropy: 2.23 bits (+- 0.71)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 7/9 (rmarm)\n",
      "Biposelet accuracy: 0.6500\n",
      "Prediction entropy: 1.92 bits (+- 0.67)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 8/9 (rlarm)\n",
      "Biposelet accuracy: 0.7098\n",
      "Prediction entropy: 1.66 bits (+- 0.67)\n",
      "Uniform entropy would be 6.64 bits\n",
      "\n",
      "\n",
      "Working on subpose 9/9 (rhand)\n",
      "Biposelet accuracy: 0.5686\n",
      "Prediction entropy: 2.31 bits (+- 0.83)\n",
      "Uniform entropy would be 6.64 bits\n"
     ]
    }
   ],
   "source": [
    "print('On validation set:')\n",
    "evaluate_preds(all_val_preds, all_val_gt)\n",
    "print('\\n\\n\\n\\nOn training set:')\n",
    "evaluate_preds(all_train_preds, all_train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of label 0 (purported type shols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of label 1 (purported type luarm):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance of label 2 (purported type lmarm):\n"
     ]
    },
   ],
   "source": [
    "# Plot one instance of each subpose just to confirm that they're correct\n",
    "for sp_idx, sp_name in enumerate(target_names[1:]):\n",
    "    print('Instance of label %i (purported type %s):' % (sp_idx, sp_name))\n",
    "    start = 100 * sp_idx + 1\n",
    "    end = start + 100\n",
    "    am_gt = argmax_preds(train_gt)\n",
    "    matching_idxs, = np.nonzero((am_gt >= start) & (am_gt < end))\n",
    "    to_get = matching_idxs[0]\n",
    "    assert isinstance(to_get, int)\n",
    "    im = train_h5['images'][to_get, 0:3, :, :].transpose((1, 2, 0))\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
